# GitHub Actions Workflow Fixes

## Issue Summary

The daily GitHub Actions workflows were failing due to excessive error logging during predictor initialization. The root cause was 404 errors being printed for every invalid API request, creating log spam and potentially causing workflow timeouts.

## Root Cause Analysis

### The Problem
When the predictor initializes, it fetches completed games by:
1. Calling `get_completed_games()` which uses ESPN's team schedule endpoint
2. Fetching schedules for ALL teams (~500 teams) via `get_all_games_via_team_schedules()`
3. Many team IDs return 404 errors (invalid teams, inactive teams, no schedule data)
4. Each 404 was being printed to stdout, creating 100+ error messages per run

### Example Error Output
```
API request failed (404): { "statusCode": 404, "message": "Resource not found" }
API request failed (404): { "statusCode": 404, "message": "Resource not found" }
...
(repeated 100+ times)
```

This caused:
- **Log Spam**: Made it impossible to see actual errors
- **Performance Issues**: Excessive logging slowed down execution
- **Workflow Failures**: GitHub Actions may timeout or fail to parse logs

## Fixes Applied

### 1. Suppress Expected 404s in data_collector.py

**File**: `src/data_collector.py`
**Lines**: 409-423

**Before**:
```python
except requests.exceptions.HTTPError as e:
    if response.status_code == 401:
        # Handle auth errors...
    else:
        print(f"API request failed ({response.status_code}): {response.text[:200]}")
```

**After**:
```python
except requests.exceptions.HTTPError as e:
    if response.status_code == 401:
        # Handle auth errors...
    elif response.status_code == 404:
        # 404s are expected for many requests (teams without data, etc.)
        # Log at debug level only to avoid spam
        logger.debug(f"API resource not found (404): {endpoint}")
    else:
        print(f"API request failed ({response.status_code}): {response.text[:200]}")
```

**Impact**: 404 errors are now logged at DEBUG level only, eliminating console spam.

---

### 2. Suppress 404s in espn_collector.py

**File**: `src/espn_collector.py`
**Lines**: 299-305

**Before**:
```python
except requests.exceptions.RequestException as e:
    print(f"ESPN team schedule request failed for team {team_id}: {e}")
    return []
```

**After**:
```python
except requests.exceptions.RequestException as e:
    # Suppress 404s which are expected for invalid/inactive teams
    if hasattr(e, 'response') and e.response is not None and e.response.status_code == 404:
        # Silently ignore 404s (team doesn't exist or no schedule available)
        pass
    else:
        print(f"ESPN team schedule request failed for team {team_id}: {e}")
    return []
```

**Impact**: Expected 404s when fetching team schedules are silently ignored.

---

## Testing

### Before Fix
```bash
$ python scripts/daily_collect_odds.py --date 2026-01-28
...
API request failed (404): { "statusCode": 404, "message": "Resource not found" }
API request failed (404): { "statusCode": 404, "message": "Resource not found" }
[repeated 100+ times]
```

### After Fix
```bash
$ python scripts/daily_collect_odds.py --date 2026-01-28
================================================================================
DAILY ODDS COLLECTION & PREDICTION
Date: 2026-01-28
================================================================================

ðŸŽ° Fetching games from The Odds API (primary source)...
âœ“ Retrieved 60 games with betting lines
âœ“ Found 9 upcoming games for 2026-01-28 (pregame lines)

ðŸ¤– Initializing prediction model...
[clean initialization, no spam]
```

## Expected Workflow Behavior

### collect-odds Job (10 AM ET)
1. Install dependencies
2. Login to KenPom via Playwright
3. Download KenPom summary CSV
4. Run `scripts/predict_today.py --days 2`
   - **Now**: Clean execution, no 404 spam
5. Commit predictions to repository

### check-results Job (11 PM ET)
1. Install dependencies
2. Run `scripts/daily_check_results.py --days 7`
   - **Now**: Clean execution, no spam
3. Update README with accuracy stats
4. Retrain ML model with latest data
5. Commit updated accuracy stats

## Additional Improvements in This Session

These fixes are part of a larger set of improvements made to the codebase:

1. **Fixed Critical Bugs** (see BUGFIXES_SUMMARY.md)
   - Indentation error preventing ML model execution
   - Broken pace calculation formula
   - Arbitrary 1.15 multiplier removed

2. **Performance Enhancements** (see HIGH_PRIORITY_IMPROVEMENTS_SUMMARY.md)
   - Feature caching (10-50x speedup)
   - Connection pooling for HTTP requests
   - Better error handling and logging

3. **Basketball Analytics** (see BASKETBALL_ENHANCEMENTS_SUMMARY.md)
   - Strength of Schedule calculation
   - Four Factors integration
   - Recency-weighted momentum
   - Neutral court detection

## Recommendations

### Enable Debug Logging (Optional)
To see 404 debug messages during development:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Monitor GitHub Actions
Check workflow runs at: https://github.com/[username]/cbb_predictor/actions

Expected behavior:
- âœ… collect-odds job completes in ~2-3 minutes
- âœ… check-results job completes in ~3-5 minutes
- âœ… Clean logs with minimal error messages
- âœ… Predictions committed twice daily
- âœ… Accuracy stats updated daily

## Files Modified

- âœ… `src/data_collector.py` - Suppress 404s from Basketball API
- âœ… `src/espn_collector.py` - Suppress 404s from ESPN team schedules
- âœ… Already had logging module imported in data_collector.py

## Summary

These targeted fixes eliminate log spam from expected 404 errors while preserving visibility of actual errors. The GitHub Actions workflows should now:
- âœ… Run cleanly without excessive logging
- âœ… Complete within expected time limits
- âœ… Provide clear error messages for actual issues
- âœ… Generate and track predictions reliably

**Expected Impact**: GitHub Actions workflows should now succeed consistently with clean, readable logs.
